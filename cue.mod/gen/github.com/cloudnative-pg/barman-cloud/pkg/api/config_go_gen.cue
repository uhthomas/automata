// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/cloudnative-pg/barman-cloud/pkg/api

package api

import machineryapi "github.com/cloudnative-pg/machinery/pkg/api"

// EncryptionType encapsulated the available types of encryption
#EncryptionType: string // #enumEncryptionType

#enumEncryptionType:
	#EncryptionTypeNone |
	#EncryptionTypeAES256 |
	#EncryptionTypeNoneAWSKMS

// EncryptionTypeNone means just use the bucket configuration
#EncryptionTypeNone: #EncryptionType & ""

// EncryptionTypeAES256 means to use AES256 encryption
#EncryptionTypeAES256: #EncryptionType & "AES256"

// EncryptionTypeNoneAWSKMS means to use aws:kms encryption
#EncryptionTypeNoneAWSKMS: #EncryptionType & "aws:kms"

// CompressionType encapsulates the available types of compression
#CompressionType: string // #enumCompressionType

#enumCompressionType:
	#CompressionTypeNone |
	#CompressionTypeGzip |
	#CompressionTypeBzip2 |
	#CompressionTypeSnappy

// CompressionTypeNone means no compression is performed
#CompressionTypeNone: #CompressionType & ""

// CompressionTypeGzip means gzip compression is performed
#CompressionTypeGzip: #CompressionType & "gzip"

// CompressionTypeBzip2 means bzip2 compression is performed
#CompressionTypeBzip2: #CompressionType & "bzip2"

// CompressionTypeSnappy means snappy compression is performed
#CompressionTypeSnappy: #CompressionType & "snappy"

// BarmanCredentials an object containing the potential credentials for each cloud provider
#BarmanCredentials: {
	// The credentials to use to upload data to Google Cloud Storage
	// +optional
	googleCredentials?: null | #GoogleCredentials @go(Google,*GoogleCredentials)

	// The credentials to use to upload data to S3
	// +optional
	s3Credentials?: null | #S3Credentials @go(AWS,*S3Credentials)

	// The credentials to use to upload data to Azure Blob Storage
	// +optional
	azureCredentials?: null | #AzureCredentials @go(Azure,*AzureCredentials)
}

// S3Credentials is the type for the credentials to be used to upload
// files to S3. It can be provided in two alternative ways:
//
// - explicitly passing accessKeyId and secretAccessKey
//
// - inheriting the role from the pod environment by setting inheritFromIAMRole to true
#S3Credentials: {
	// The reference to the access key id
	// +optional
	accessKeyId?: null | machineryapi.#SecretKeySelector @go(AccessKeyIDReference,*machineryapi.SecretKeySelector)

	// The reference to the secret access key
	// +optional
	secretAccessKey?: null | machineryapi.#SecretKeySelector @go(SecretAccessKeyReference,*machineryapi.SecretKeySelector)

	// The reference to the secret containing the region name
	// +optional
	region?: null | machineryapi.#SecretKeySelector @go(RegionReference,*machineryapi.SecretKeySelector)

	// The references to the session key
	// +optional
	sessionToken?: null | machineryapi.#SecretKeySelector @go(SessionToken,*machineryapi.SecretKeySelector)

	// Use the role based authentication without providing explicitly the keys.
	// +optional
	inheritFromIAMRole?: bool @go(InheritFromIAMRole)
}

// AzureCredentials is the type for the credentials to be used to upload
// files to Azure Blob Storage. The connection string contains every needed
// information. If the connection string is not specified, we'll need the
// storage account name and also one (and only one) of:
//
// - storageKey
// - storageSasToken
//
// - inheriting the credentials from the pod environment by setting inheritFromAzureAD to true
#AzureCredentials: {
	// The connection string to be used
	// +optional
	connectionString?: null | machineryapi.#SecretKeySelector @go(ConnectionString,*machineryapi.SecretKeySelector)

	// The storage account where to upload data
	// +optional
	storageAccount?: null | machineryapi.#SecretKeySelector @go(StorageAccount,*machineryapi.SecretKeySelector)

	// The storage account key to be used in conjunction
	// with the storage account name
	// +optional
	storageKey?: null | machineryapi.#SecretKeySelector @go(StorageKey,*machineryapi.SecretKeySelector)

	// A shared-access-signature to be used in conjunction with
	// the storage account name
	// +optional
	storageSasToken?: null | machineryapi.#SecretKeySelector @go(StorageSasToken,*machineryapi.SecretKeySelector)

	// Use the Azure AD based authentication without providing explicitly the keys.
	// +optional
	inheritFromAzureAD?: bool @go(InheritFromAzureAD)
}

// GoogleCredentials is the type for the Google Cloud Storage credentials.
// This needs to be specified even if we run inside a GKE environment.
#GoogleCredentials: {
	// The secret containing the Google Cloud Storage JSON file with the credentials
	// +optional
	applicationCredentials?: null | machineryapi.#SecretKeySelector @go(ApplicationCredentials,*machineryapi.SecretKeySelector)

	// If set to true, will presume that it's running inside a GKE environment,
	// default to false.
	// +optional
	gkeEnvironment?: bool @go(GKEEnvironment)
}

// BarmanObjectStoreConfiguration contains the backup configuration
// using Barman against an S3-compatible object storage
#BarmanObjectStoreConfiguration: {
	#BarmanCredentials

	// Endpoint to be used to upload data to the cloud,
	// overriding the automatic endpoint discovery
	// +optional
	endpointURL?: string @go(EndpointURL)

	// EndpointCA store the CA bundle of the barman endpoint.
	// Useful when using self-signed certificates to avoid
	// errors with certificate issuer and barman-cloud-wal-archive
	// +optional
	endpointCA?: null | machineryapi.#SecretKeySelector @go(EndpointCA,*machineryapi.SecretKeySelector)

	// The path where to store the backup (i.e. s3://bucket/path/to/folder)
	// this path, with different destination folders, will be used for WALs
	// and for data
	// +kubebuilder:validation:MinLength=1
	destinationPath: string @go(DestinationPath)

	// The server name on S3, the cluster name is used if this
	// parameter is omitted
	// +optional
	serverName?: string @go(ServerName)

	// The configuration for the backup of the WAL stream.
	// When not defined, WAL files will be stored uncompressed and may be
	// unencrypted in the object store, according to the bucket default policy.
	// +optional
	wal?: null | #WalBackupConfiguration @go(Wal,*WalBackupConfiguration)

	// The configuration to be used to backup the data files
	// When not defined, base backups files will be stored uncompressed and may
	// be unencrypted in the object store, according to the bucket default
	// policy.
	// +optional
	data?: null | #DataBackupConfiguration @go(Data,*DataBackupConfiguration)

	// Tags is a list of key value pairs that will be passed to the
	// Barman --tags option.
	// +optional
	tags?: {[string]: string} @go(Tags,map[string]string)

	// HistoryTags is a list of key value pairs that will be passed to the
	// Barman --history-tags option.
	// +optional
	historyTags?: {[string]: string} @go(HistoryTags,map[string]string)
}

// WalBackupConfiguration is the configuration of the backup of the
// WAL stream
#WalBackupConfiguration: {
	// Compress a WAL file before sending it to the object store. Available
	// options are empty string (no compression, default), `gzip`, `bzip2` or `snappy`.
	// +kubebuilder:validation:Enum=gzip;bzip2;snappy
	// +optional
	compression?: #CompressionType @go(Compression)

	// Whenever to force the encryption of files (if the bucket is
	// not already configured for that).
	// Allowed options are empty string (use the bucket policy, default),
	// `AES256` and `aws:kms`
	// +kubebuilder:validation:Enum=AES256;"aws:kms"
	// +optional
	encryption?: #EncryptionType @go(Encryption)

	// Number of WAL files to be either archived in parallel (when the
	// PostgreSQL instance is archiving to a backup object store) or
	// restored in parallel (when a PostgreSQL standby is fetching WAL
	// files from a recovery object store). If not specified, WAL files
	// will be processed one at a time. It accepts a positive integer as a
	// value - with 1 being the minimum accepted value.
	// +kubebuilder:validation:Minimum=1
	// +optional
	maxParallel?: int @go(MaxParallel)

	// Additional arguments that can be appended to the 'barman-cloud-wal-archive'
	// command-line invocation. These arguments provide flexibility to customize
	// the WAL archive process further, according to specific requirements or configurations.
	//
	// Example:
	// In a scenario where specialized backup options are required, such as setting
	// a specific timeout or defining custom behavior, users can use this field
	// to specify additional command arguments.
	//
	// Note:
	// It's essential to ensure that the provided arguments are valid and supported
	// by the 'barman-cloud-wal-archive' command, to avoid potential errors or unintended
	// behavior during execution.
	// +optional
	archiveAdditionalCommandArgs?: [...string] @go(ArchiveAdditionalCommandArgs,[]string)

	// Additional arguments that can be appended to the 'barman-cloud-wal-restore'
	// command-line invocation. These arguments provide flexibility to customize
	// the WAL restore process further, according to specific requirements or configurations.
	//
	// Example:
	// In a scenario where specialized backup options are required, such as setting
	// a specific timeout or defining custom behavior, users can use this field
	// to specify additional command arguments.
	//
	// Note:
	// It's essential to ensure that the provided arguments are valid and supported
	// by the 'barman-cloud-wal-restore' command, to avoid potential errors or unintended
	// behavior during execution.
	// +optional
	restoreAdditionalCommandArgs?: [...string] @go(RestoreAdditionalCommandArgs,[]string)
}

// DataBackupConfiguration is the configuration of the backup of
// the data directory
#DataBackupConfiguration: {
	// Compress a backup file (a tar file per tablespace) while streaming it
	// to the object store. Available options are empty string (no
	// compression, default), `gzip`, `bzip2` or `snappy`.
	// +kubebuilder:validation:Enum=gzip;bzip2;snappy
	// +optional
	compression?: #CompressionType @go(Compression)

	// Whenever to force the encryption of files (if the bucket is
	// not already configured for that).
	// Allowed options are empty string (use the bucket policy, default),
	// `AES256` and `aws:kms`
	// +kubebuilder:validation:Enum=AES256;"aws:kms"
	// +optional
	encryption?: #EncryptionType @go(Encryption)

	// The number of parallel jobs to be used to upload the backup, defaults
	// to 2
	// +kubebuilder:validation:Minimum=1
	// +optional
	jobs?: null | int32 @go(Jobs,*int32)

	// Control whether the I/O workload for the backup initial checkpoint will
	// be limited, according to the `checkpoint_completion_target` setting on
	// the PostgreSQL server. If set to true, an immediate checkpoint will be
	// used, meaning PostgreSQL will complete the checkpoint as soon as
	// possible. `false` by default.
	// +optional
	immediateCheckpoint?: bool @go(ImmediateCheckpoint)

	// AdditionalCommandArgs represents additional arguments that can be appended
	// to the 'barman-cloud-backup' command-line invocation. These arguments
	// provide flexibility to customize the backup process further according to
	// specific requirements or configurations.
	//
	// Example:
	// In a scenario where specialized backup options are required, such as setting
	// a specific timeout or defining custom behavior, users can use this field
	// to specify additional command arguments.
	//
	// Note:
	// It's essential to ensure that the provided arguments are valid and supported
	// by the 'barman-cloud-backup' command, to avoid potential errors or unintended
	// behavior during execution.
	// +optional
	additionalCommandArgs?: [...string] @go(AdditionalCommandArgs,[]string)
}
